# PanSou 缓存系统设计详解

## 1. 缓存系统概述

缓存系统是PanSou性能优化的核心组件，通过增强版两级缓存（内存+分片磁盘）机制，大幅提升重复查询的响应速度。该系统采用分层设计，实现了高效的缓存存取和智能的缓存策略。

PanSou的缓存系统包括两个主要部分：
1. **通用缓存系统**：用于API响应和常规搜索结果缓存
2. **异步插件缓存系统**：专为异步插件设计的高级缓存机制

## 2. 目录结构

```
pansou/util/cache/
├── cache_key.go       # 优化的缓存键生成
├── cache_key_test.go  # 缓存键单元测试
├── disk_cache.go      # 磁盘缓存实现
├── sharded_disk_cache.go # 分片磁盘缓存实现
├── two_level_cache.go # 两级缓存实现
├── enhanced_two_level_cache.go # 增强版两级缓存实现
├── serializer.go      # 序列化器接口
├── utils.go           # 缓存工具函数
└── utils_test.go      # 缓存工具测试

pansou/plugin/
├── baseasyncplugin.go # 异步插件缓存实现

pansou/util/json/
└── json.go            # 基于sonic的高性能JSON处理封装
```

## 3. 缓存架构设计

### 3.1 增强版两级缓存架构

PanSou采用增强版两级缓存架构，包括内存缓存和分片磁盘缓存：

```
┌─────────────────────────┐
│      搜索请求           │
└───────────┬─────────────┘
            │
┌───────────▼─────────────┐
│     缓存键生成          │
└───────────┬─────────────┘
            │
┌───────────▼─────────────┐
│     内存缓存查询        │
└───────────┬─────────────┘
            │ (未命中)
┌───────────▼─────────────┐
│   分片磁盘缓存查询      │
└───────────┬─────────────┘
            │ (未命中)
┌───────────▼─────────────┐
│     执行搜索            │
└───────────┬─────────────┘
            │
┌───────────▼─────────────┐
│     更新内存缓存        │
└───────────┬─────────────┘
            │
┌───────────▼─────────────┐
│  异步更新分片磁盘缓存   │
└─────────────────────────┘
```

### 3.2 缓存层次职责

1. **内存缓存**：
   - 提供快速访问
   - 存储热点数据
   - 减少磁盘I/O

2. **分片磁盘缓存**：
   - 提供持久存储
   - 分片存储提高并发性能
   - 减少锁竞争
   - 在服务重启后保留缓存

3. **序列化器**：
   - 提供统一的序列化/反序列化接口
   - 支持多种序列化方式（Gob和JSON）
   - 优化序列化性能

## 4. 缓存键设计

### 4.1 分离的缓存键生成

缓存键生成是缓存系统的基础，决定了缓存的命中率和有效性。PanSou实现了分离的缓存键生成策略，为TG搜索和插件搜索生成独立的缓存键。

```go
// GenerateTGCacheKey 为TG搜索生成缓存键
func GenerateTGCacheKey(keyword string, channels []string) string {
    // 关键词标准化
    normalizedKeyword := strings.ToLower(strings.TrimSpace(keyword))
    
    // 获取频道列表哈希
    channelsHash := getChannelsHash(channels)
    
    // 生成TG搜索特定的缓存键
    keyStr := fmt.Sprintf("tg:%s:%s", normalizedKeyword, channelsHash)
    hash := md5.Sum([]byte(keyStr))
    return hex.EncodeToString(hash[:])
}

// GeneratePluginCacheKey 为插件搜索生成缓存键
func GeneratePluginCacheKey(keyword string, plugins []string) string {
    // 关键词标准化
    normalizedKeyword := strings.ToLower(strings.TrimSpace(keyword))
    
    // 获取插件列表哈希
    pluginsHash := getPluginsHash(plugins)
    
    // 生成插件搜索特定的缓存键
    keyStr := fmt.Sprintf("plugin:%s:%s", normalizedKeyword, pluginsHash)
    hash := md5.Sum([]byte(keyStr))
    return hex.EncodeToString(hash[:])
}
```

### 4.2 缓存键设计思想

1. **标准化处理**：对关键词进行标准化，确保相同语义的查询使用相同的缓存键
2. **参数敏感**：缓存键包含影响结果的参数（如搜索频道、插件列表），避免错误的缓存命中
3. **排序处理**：对数组参数进行排序，确保参数顺序不同但内容相同的查询使用相同的缓存键
4. **哈希处理**：对大型列表使用哈希处理，减小缓存键长度，提高性能
5. **参数规范化**：统一处理不同形式但语义相同的参数，提高缓存命中率
6. **分离策略**：为TG搜索和插件搜索生成独立的缓存键，实现独立更新

### 4.3 列表参数处理

```go
// 获取或计算插件哈希
func getPluginsHash(plugins []string) string {
    // 检查是否为空列表
    if plugins == nil || len(plugins) == 0 {
        // 使用预计算的所有插件哈希
        if hash, ok := precomputedHashes.Load("all_plugins"); ok {
            return hash.(string)
        }
        return allPluginsHash
    }
    
    // 检查是否有空字符串元素
    hasNonEmptyPlugin := false
    for _, p := range plugins {
        if p != "" {
            hasNonEmptyPlugin = true
            break
        }
    }
    
    // 如果全是空字符串，也视为空列表
    if !hasNonEmptyPlugin {
        if hash, ok := precomputedHashes.Load("all_plugins"); ok {
            return hash.(string)
        }
        return allPluginsHash
    }
    
    // 对于小型列表，直接使用字符串连接
    if len(plugins) < 5 {
        pluginsCopy := make([]string, 0, len(plugins))
        for _, p := range plugins {
            if p != "" { // 忽略空字符串
                pluginsCopy = append(pluginsCopy, p)
            }
        }
        sort.Strings(pluginsCopy)
        
        // 检查是否有预计算的哈希
        key := strings.Join(pluginsCopy, ",")
        if hash, ok := precomputedHashes.Load("plugins:"+key); ok {
            return hash.(string)
        }
        
        return strings.Join(pluginsCopy, ",")
    }
    
    // 生成排序后的字符串用作键，忽略空字符串
    pluginsCopy := make([]string, 0, len(plugins))
    for _, p := range plugins {
        if p != "" { // 忽略空字符串
            pluginsCopy = append(pluginsCopy, p)
        }
    }
    sort.Strings(pluginsCopy)
    key := strings.Join(pluginsCopy, ",")
    
    // 尝试从缓存获取
    if hash, ok := pluginHashCache.Load(key); ok {
        return hash.(string)
    }
    
    // 计算哈希
    hash := calculateListHash(pluginsCopy)
    
    // 存入缓存
    pluginHashCache.Store(key, hash)
    return hash
}
```

### 4.4 预计算哈希优化

```go
// 初始化预计算的哈希值
func init() {
    // 预计算空列表的哈希值
    precomputedHashes.Store("empty_channels", "all")
    
    // 预计算常用的频道组合哈希值
    commonChannels := [][]string{
        {"dongman", "anime"},
        {"movie", "film"},
        {"music", "audio"},
        {"book", "ebook"},
    }
    
    for _, channels := range commonChannels {
        key := strings.Join(channels, ",")
        hash := calculateListHash(channels)
        precomputedHashes.Store("channels:"+key, hash)
    }
    
    // 预计算常用的插件组合哈希值
    commonPlugins := [][]string{
        {"pan666", "panta"},
        {"aliyun", "baidu"},
    }
    
    for _, plugins := range commonPlugins {
        key := strings.Join(plugins, ",")
        hash := calculateListHash(plugins)
        precomputedHashes.Store("plugins:"+key, hash)
    }
    
    // 预计算所有插件的哈希值
    allPlugins := plugin.GetRegisteredPlugins()
    allPluginNames := make([]string, 0, len(allPlugins))
    for _, p := range allPlugins {
        allPluginNames = append(allPluginNames, p.Name())
    }
    sort.Strings(allPluginNames)
    allPluginsHash = calculateListHash(allPluginNames)
    precomputedHashes.Store("all_plugins", allPluginsHash)
}
```

## 5. 缓存一致性优化

### 5.1 参数规范化处理

为确保不同形式但语义相同的参数生成相同的缓存键，系统实现了以下规范化处理：

1. **插件参数规范化**：
   - 不传plugins参数
   - 传空plugins数组
   - 传只包含空字符串的plugins数组
   
   以上三种情况都视为未指定插件，使用相同的缓存键。

2. **频道参数规范化**：
   - 不传channels参数
   - 传空channels数组
   - 传只包含空字符串的channels数组
   
   以上三种情况都视为使用默认频道，使用相同的缓存键。

3. **关键词规范化**：
   - 去除前后空格
   - 转换为小写
   - 保留中间空格（支持多关键词搜索）

### 5.2 缓存数据时间戳检查

为了确保即使在不强制刷新的情况下也能获取最新的缓存数据，系统实现了缓存数据时间戳检查机制：

```go
// 检查缓存数据是否是最新的
if len(results) > 0 {
    // 获取当前时间
    now := time.Now()
    // 检查缓存数据是否是最近更新的
    // 这里我们假设如果缓存数据中有结果的时间戳在过去30秒内，则认为是最新的
    for _, result := range results {
        if !result.Datetime.IsZero() && now.Sub(result.Datetime) < 30*time.Second {
            return results, nil
        }
    }
}
```

这种机制特别适用于异步插件，因为异步插件会在后台持续更新缓存数据。通过时间戳检查，系统能够确保用户总是获取到最新的搜索结果，同时保持良好的性能。

## 6. 分片磁盘缓存

### 6.1 分片磁盘缓存设计

分片磁盘缓存通过将缓存数据分散到多个子目录中，解决了高并发场景下的锁竞争问题。

```go
// ShardedDiskCache 分片磁盘缓存
type ShardedDiskCache struct {
    baseDir     string
    shardCount  int
    shards      []*DiskCache
    maxSizeMB   int
    mutex       sync.RWMutex
}

// NewShardedDiskCache 创建新的分片磁盘缓存
func NewShardedDiskCache(baseDir string, shardCount, maxSizeMB int) (*ShardedDiskCache, error) {
    // 确保每个分片的大小合理
    shardSize := maxSizeMB / shardCount
    if shardSize < 1 {
        shardSize = 1
    }
    
    cache := &ShardedDiskCache{
        baseDir:    baseDir,
        shardCount: shardCount,
        shards:     make([]*DiskCache, shardCount),
        maxSizeMB:  maxSizeMB,
    }
    
    // 初始化每个分片
    for i := 0; i < shardCount; i++ {
        shardPath := filepath.Join(baseDir, fmt.Sprintf("shard_%d", i))
        diskCache, err := NewDiskCache(shardPath, shardSize)
        if err != nil {
            return nil, err
        }
        cache.shards[i] = diskCache
    }
    
    return cache, nil
}

// 获取键对应的分片
func (c *ShardedDiskCache) getShard(key string) *DiskCache {
    // 计算哈希值决定分片
    h := fnv.New32a()
    h.Write([]byte(key))
    shardIndex := int(h.Sum32()) % c.shardCount
    return c.shards[shardIndex]
}
```

### 6.2 分片磁盘缓存优势

1. **减少锁竞争**：每个分片有自己的锁，减少了高并发场景下的锁竞争
2. **提高并发性能**：多个请求可以同时访问不同的分片，提高并发性能
3. **均衡负载**：通过哈希算法将缓存键均匀分布到不同分片，实现负载均衡
4. **隔离故障**：单个分片的故障不会影响其他分片的正常运行

## 7. 序列化器接口

### 7.1 序列化器设计

序列化器接口统一了序列化和反序列化操作，支持多种序列化方式。

```go
// Serializer 序列化接口
type Serializer interface {
    Serialize(v interface{}) ([]byte, error)
    Deserialize(data []byte, v interface{}) error
}

// GobSerializer 使用gob进行序列化/反序列化
type GobSerializer struct {
    bufferPool sync.Pool
}

// JSONSerializer 使用JSON进行序列化/反序列化
type JSONSerializer struct {
    // 使用sonic库提高性能
}
```

### 7.2 Gob序列化优势

相比JSON序列化，Gob序列化具有以下优势：

1. **更高的性能**：Gob序列化/反序列化速度更快
2. **更小的结果大小**：Gob序列化结果通常比JSON更小
3. **更好的Go类型支持**：Gob是Go语言原生的序列化格式，对Go类型支持更好

### 7.3 类型注册

为了确保Gob序列化器能正确处理所有类型，系统在初始化时注册了所有需要的类型：

```go
func init() {
    // 注册model包中的所有类型
    gob.Register(model.SearchResult{})
    gob.Register(model.SearchResponse{})
    gob.Register(model.Link{})
    gob.Register(model.MergedLink{})
    gob.Register(map[string][]model.MergedLink{})
    gob.Register([]model.SearchResult{})
    gob.Register(time.Time{})
}
```

## 8. 增强版两级缓存

### 8.1 增强版两级缓存设计

增强版两级缓存结合了内存缓存、分片磁盘缓存和可配置的序列化器。

```go
// EnhancedTwoLevelCache 增强版两级缓存
type EnhancedTwoLevelCache struct {
    memory     *MemoryCache
    disk       *ShardedDiskCache
    mutex      sync.RWMutex
    serializer Serializer
}

// NewEnhancedTwoLevelCache 创建新的增强版两级缓存
func NewEnhancedTwoLevelCache() (*EnhancedTwoLevelCache, error) {
    // 创建内存缓存
    memory := NewMemoryCache(config.AppConfig.MemoryCacheSize)
    
    // 创建分片磁盘缓存
    disk, err := NewShardedDiskCache(
        config.AppConfig.CachePath,
        config.AppConfig.ShardCount,
        config.AppConfig.CacheMaxSizeMB,
    )
    if err != nil {
        return nil, err
    }
    
    // 创建Gob序列化器
    serializer := NewGobSerializer()
    
    return &EnhancedTwoLevelCache{
        memory:     memory,
        disk:       disk,
        serializer: serializer,
    }, nil
}
```

### 8.2 增强版两级缓存方法

```go
// Get 从缓存获取数据
func (c *EnhancedTwoLevelCache) Get(key string) ([]byte, bool, error) {
    // 先从内存缓存获取
    data, ok := c.memory.Get(key)
    if ok {
        return data, true, nil
    }
    
    // 内存缓存未命中，从磁盘缓存获取
    data, ok, err := c.disk.Get(key)
    if err != nil {
        return nil, false, err
    }
    
    if ok {
        // 将数据放入内存缓存
        c.memory.Set(key, data)
        return data, true, nil
    }
    
    return nil, false, nil
}

// Set 将数据存入缓存
func (c *EnhancedTwoLevelCache) Set(key string, data []byte, ttl time.Duration) error {
    // 存入内存缓存
    c.memory.Set(key, data)
    
    // 异步存入磁盘缓存
    go func() {
        c.disk.Set(key, data, ttl)
    }()
    
    return nil
}

// GetSerializer 获取序列化器
func (c *EnhancedTwoLevelCache) GetSerializer() Serializer {
    return c.serializer
}
```

### 8.3 双缓存机制

为了确保系统平稳过渡，PanSou实现了双缓存机制：

```go
// 优先使用增强版缓存
if enhancedTwoLevelCache != nil {
    data, hit, err = enhancedTwoLevelCache.Get(cacheKey)
    
    if err == nil && hit {
        var results []model.SearchResult
        if err := enhancedTwoLevelCache.GetSerializer().Deserialize(data, &results); err == nil {
            return results, nil
        }
    }
} else if twoLevelCache != nil {
    // 如果增强版缓存不可用，回退到原始缓存
    data, hit, err = twoLevelCache.Get(cacheKey)
    
    if err == nil && hit {
        var results []model.SearchResult
        if err := cache.DeserializeWithPool(data, &results); err == nil {
            return results, nil
        }
    }
}
```

## 9. 异步插件缓存系统

### 9.1 异步插件缓存设计

异步插件缓存系统实现了"尽快响应，持续处理"的异步模式，包括以下特性：

1. **双通道处理**：同时启动快速响应通道和后台处理通道
2. **超时控制**：在响应超时时返回当前结果，后台继续处理
3. **缓存更新**：后台处理完成后更新缓存，供后续查询使用
4. **增量更新**：新旧结果智能合并，保留唯一标识符不同的结果

### 9.2 缓存数据时间戳检查

为了确保即使在不强制刷新的情况下也能获取最新的缓存数据，系统实现了缓存数据时间戳检查机制：

```go
// searchPlugins 方法中的缓存数据时间戳检查
if len(results) > 0 {
    // 获取当前时间
    now := time.Now()
    // 检查缓存数据是否是最近更新的
    // 这里我们假设如果缓存数据中有结果的时间戳在过去30秒内，则认为是最新的
    for _, result := range results {
        if !result.Datetime.IsZero() && now.Sub(result.Datetime) < 30*time.Second {
            return results, nil
        }
    }
}
```

这种机制确保了用户总是能获取到异步插件在后台更新的最新缓存数据，同时保持良好的性能。

## 10. 缓存性能优化

### 10.1 内存优化

1. **对象池**：使用对象池减少内存分配和GC压力
2. **预分配容量**：为map和slice预分配容量，减少动态扩容
3. **缓冲池**：为序列化操作使用缓冲池，减少内存分配

### 10.2 并发优化

1. **分片策略**：使用分片磁盘缓存，减少锁竞争
2. **细粒度锁**：每个分片使用独立的锁，提高并发性能
3. **异步写入**：异步写入磁盘缓存，不阻塞主流程

### 10.3 序列化优化

1. **Gob序列化**：使用Gob序列化提高性能
2. **类型注册**：预先注册所有类型，避免运行时注册开销
3. **缓冲池**：使用缓冲池优化序列化过程

## 11. 缓存管理

### 11.1 缓存清理策略

1. **TTL机制**：缓存项有明确的过期时间
2. **LRU策略**：内存缓存使用LRU策略进行淘汰
3. **定期清理**：磁盘缓存定期清理过期项
4. **大小限制**：磁盘缓存有总大小限制，超过时清理最旧的项

### 11.2 缓存监控

1. **命中率统计**：记录缓存命中率
2. **大小监控**：监控缓存大小变化
3. **性能指标**：记录缓存操作的性能指标

